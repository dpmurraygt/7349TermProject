{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Alex Approach\n",
    "\n",
    "# K-anonymous clustering 2 step partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-anonymous clustering with 2- step partition approach involves 2 steps to creating a publishable-sanitized dataset. While this approach is not all that unique, it is a simpler approach to previous research that has been published.  Additionally, we also focus on the approach that picks the best clusters for the anonymized datasets.  Previously published research tends to center on picking a pre-defined algorithm or modification of a pre-defined algorithm.  Therefore, this approach is must more robust from the perspective of providing hte best clusterings we can while also balancing anonymity.  This approach will also allow for out of the box algorithms to be used with little modification.  This allows for DBAs not familiar with more complex clustering implementation to take our code and implement it immediately with few checks.  Additionally, we highlight some of the pitfalls associated with this approach as well as potential solutions to the problem.\n",
    "\n",
    "\n",
    "* First, we remove all explicit identifiers (This is our supression step).\n",
    "    - removing explicit identifiers will enable us to remove all features which allow for the specific identification of a subject.  We much weigh these items accordingly as we may be able to use some of these features in the next step while still maintaining anaonymity in the final dataset.  Items that should be removed in this step are features such as name and social security number.  We can leave attributes such as data of birth in this dataset, because we can use these values to create the groupings in the next step.\n",
    "    \n",
    "* Secondly, we will run a clustering algorithm on the remaining set of identifiers that make up the quasi-identifier of the explicitly sanitized dataset.  We will call the explicitly santized dataset the interim dataset that exists in memory between steps 1 and 2. This is our generalization step.  The explicitly santized dataset will never be shared with the broader audience as this would most certainly allow for the identification of individuals in the dataset.  \n",
    "    - Note that some identifiers may not be quantitative and may need to be discretized of simply thrown out.  We always err on the side of conservatism in this approach.  \n",
    "    - Once the clusters are run, we gather the ranges of values that are representative within each of the clusters.  We should note that in some cases, we may have overlapping values within the clusters.  In this case, we should either add futher discretization to the clustering feature groups or we could manually discretize and resort within the initialization cluster.  If this step is taken, we must test for that feature representation combination to still retain k-ananymous groupings.  While this step introduces a somewhat manual solution to anonymization within the automated step, it ensures that publishers are studying the data that they put out for public consumption and avoids adding considerable amounts of complexity to the existing algorithm\n",
    "\n",
    "* Once generalization is complete, we can then create the table of published clusters and paired tuple data.  In this case, we are actually going to publish 2 datasets.  One dataset will be our cluster groupings.  The other dataset will be our tuple-level dataset that contains the original number of N records.  The cartesian product of these 2 recordsets allows for the creation of a single cohesive dataset that contains k-1 values for each of the aggregated groupings within the dataset.  That being said, the initial statistical significance of the resultant dataset is retained at the level of specificity that is allowed within the cluster.  This is an important point to note.  This approach allows us to control the level of depth to which a given datset can be deduced.  This adds another level of anonymity in a sense.  If the clustered quasi-identifier is infact more anaonymous than necessary, then the publisher is actually able to further anonymize the dataset.  This is an important feature as it allows for the publishing of data that is increasingly sensitive.  That being said, this increases the level of responsibility relegated to the data publisher.  This point brings us to the next step in our publishability checks\n",
    "\n",
    "* Once the clusters have been checked for k-anonymous groupings, the publisher needs to maintain a series of checks and databases upon which to check the data against in pre-publication. This ensures that attackers will not be able to mate up information.  The publisher should maintain 3 series of databases against which to check the datasrouces.  It should also be noted that this can be done algorithmically so that the publisher need not rewrite the process with each iteration. The database type breakdown is as follows:\n",
    "    - Datasources previously published by the publisher\n",
    "    - Datasources previously published by sources other than the publisher\n",
    "    - Datasources previously published by public entities \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# hypothetical k-anonymous 2-step partition\n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats \n",
    "import sklearn as sk\n",
    "import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from pandas.tools.plotting import scatter_plot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Lars, SGDRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn import metrics as mt\n",
    "#from crypt import AES\n",
    "import random\n",
    "\n",
    "\n",
    "#import locale\n",
    "#locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#configure the random seed so we our randomness is reproducible for selection of learn/test sets\n",
    "np.random.seed(0)\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first load the dataset in, we will combine the 2 datasets needed, this is not part of the anonymization process\n",
    "\n",
    "# NOTE: These records are 100% hypothetical Public airline records were taken and joined with completely randomized \n",
    "# data.  All birthdates, genders, and zipcodes were generated with random algorithms.  All names were taken combined\n",
    "# from the US census bureau's lists of male first names, female first names, and lastnames from the 1990 U.S. census\n",
    "\n",
    "customers = pd.read_csv('customer.csv')\n",
    "\n",
    "customer_flights = pd.read_csv('cust_flight.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7) (53027, 5)\n"
     ]
    }
   ],
   "source": [
    "print( customers.shape, customer_flights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>flight_route_number</th>\n",
       "      <th>customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHX</td>\n",
       "      <td>STL</td>\n",
       "      <td>5/30/2016</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAL</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>5/19/2016</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAK</td>\n",
       "      <td>SAN</td>\n",
       "      <td>5/9/2016</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAN</td>\n",
       "      <td>BNA</td>\n",
       "      <td>5/28/2016</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SJC</td>\n",
       "      <td>SAN</td>\n",
       "      <td>5/11/2016</td>\n",
       "      <td>527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin destination departure_date  flight_route_number  customer\n",
       "0    PHX         STL      5/30/2016                  281         0\n",
       "1    DAL         ABQ      5/19/2016                   42         0\n",
       "2    OAK         SAN       5/9/2016                   18         0\n",
       "3    SAN         BNA      5/28/2016                  585         0\n",
       "4    SJC         SAN      5/11/2016                  527         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerNumber</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>TotalFlights</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>60474</td>\n",
       "      <td>0</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>JOHNSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>94066</td>\n",
       "      <td>0</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>WILLIAMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>94572</td>\n",
       "      <td>7</td>\n",
       "      <td>LINDA</td>\n",
       "      <td>JONES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2646</td>\n",
       "      <td>7</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>BROWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerNumber  Gender  Age  ZipCode  TotalFlights first_name last_name\n",
       "0               0       0   37    67570             9       KAMI     SMITH\n",
       "1               1       1   39    60474             0      JAMES   JOHNSON\n",
       "2               2       1   43    94066             0       JOHN  WILLIAMS\n",
       "3               3       0   41    94572             7      LINDA     JONES\n",
       "4               4       1   47     2646             7    MICHAEL     BROWN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's combine the 2 dataframes to work with for our anonymization\n",
    "\n",
    "\n",
    "new_customers = customer_flights.merge(right = customers, left_on = 'customer', right_on = 'CustomerNumber', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>flight_route_number</th>\n",
       "      <th>customer</th>\n",
       "      <th>CustomerNumber</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>TotalFlights</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHX</td>\n",
       "      <td>STL</td>\n",
       "      <td>5/30/2016</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAL</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>5/19/2016</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAK</td>\n",
       "      <td>SAN</td>\n",
       "      <td>5/9/2016</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAN</td>\n",
       "      <td>BNA</td>\n",
       "      <td>5/28/2016</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SJC</td>\n",
       "      <td>SAN</td>\n",
       "      <td>5/11/2016</td>\n",
       "      <td>527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>67570</td>\n",
       "      <td>9</td>\n",
       "      <td>KAMI</td>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin destination departure_date  flight_route_number  customer  \\\n",
       "0    PHX         STL      5/30/2016                  281         0   \n",
       "1    DAL         ABQ      5/19/2016                   42         0   \n",
       "2    OAK         SAN       5/9/2016                   18         0   \n",
       "3    SAN         BNA      5/28/2016                  585         0   \n",
       "4    SJC         SAN      5/11/2016                  527         0   \n",
       "\n",
       "   CustomerNumber  Gender  Age  ZipCode  TotalFlights first_name last_name  \n",
       "0               0       0   37    67570             9       KAMI     SMITH  \n",
       "1               0       0   37    67570             9       KAMI     SMITH  \n",
       "2               0       0   37    67570             9       KAMI     SMITH  \n",
       "3               0       0   37    67570             9       KAMI     SMITH  \n",
       "4               0       0   37    67570             9       KAMI     SMITH  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53027, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should see 53,027 records and 12 columns in the new dataset\n",
    "\n",
    "new_customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# great the dataset now looks good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: remove explicit identifiers - subjective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, the explicit identifiers are simple.  The name of the customer and the customer number are the only explicit identifier; therefore, we will just remove the name columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in ['first_name','last_name', 'CustomerNumber', 'customer']:\n",
    "    if col in customers:\n",
    "        del customers[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Age', 'ZipCode', 'TotalFlights']\n"
     ]
    }
   ],
   "source": [
    "print (list(customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with a series of flights taken by each customer.  We have now removed the customer specific information from the records, but we need to further anonymize so that an attacker cannot back into the information about a customer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cluster on the quasi-identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 : 123913254321.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Changing to using customers, that is a better way to do it...\n",
    "quasi_identifier = np.array(customers[['Gender','Age','ZipCode','TotalFlights']])\n",
    "\n",
    "#quasi_identifier = np.array(new_customers[['Gender']])\n",
    "\n",
    "cluster_list =  [8]\n",
    "\n",
    "\n",
    "for cluster in cluster_list:\n",
    "        cls  = KMeans(n_clusters = cluster, init = 'k-means++')\n",
    "        cls.fit(quasi_identifier)\n",
    "        labels = cls.labels_\n",
    "        \n",
    "        print( cluster, \":\", cls.inertia_ )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, mate up the customers with their cluster\n",
    "\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered_customers = np.column_stack((customers, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered_customers = pd.DataFrame(clustered_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered_customers.columns = ['Gender','Age','zipcode','total_flights', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.508500</td>\n",
       "      <td>43.442500</td>\n",
       "      <td>49828.587000</td>\n",
       "      <td>5.30270</td>\n",
       "      <td>3.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499953</td>\n",
       "      <td>4.788673</td>\n",
       "      <td>27790.168748</td>\n",
       "      <td>5.33062</td>\n",
       "      <td>2.314226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>715.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>25843.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>48410.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>73154.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>99733.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Gender           Age       zipcode  total_flights       cluster\n",
       "count  10000.000000  10000.000000  10000.000000    10000.00000  10000.000000\n",
       "mean       0.508500     43.442500  49828.587000        5.30270      3.414600\n",
       "std        0.499953      4.788673  27790.168748        5.33062      2.314226\n",
       "min        0.000000     26.000000    715.000000        0.00000      0.000000\n",
       "25%        0.000000     40.000000  25843.000000        0.00000      1.000000\n",
       "50%        1.000000     43.000000  48410.000000        4.00000      3.000000\n",
       "75%        1.000000     47.000000  73154.000000        9.00000      5.000000\n",
       "max        1.000000     60.000000  99733.000000       29.00000      7.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_customers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
